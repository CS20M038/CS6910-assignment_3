{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled27.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9FRhJZG4Tlj"
      },
      "source": [
        "#@title Import Libraries\n",
        "from random import randint\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "import keras.backend as K\n",
        "from tensorflow.keras import models\n",
        "from numpy import array_equal\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "from tensorflow.keras.layers import RepeatVector\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from scipy.ndimage.interpolation import shift\n",
        "import csv\n",
        "import random"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIaBBs1MQ3t_",
        "outputId": "da097531-7bda-41a6-c80c-80b48c6f75b8"
      },
      "source": [
        "#@title Check GPU\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('GPU device not found')\n",
        "else:\n",
        "  print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gy16qpTY4Wgr",
        "outputId": "67a55976-53b9-4e1f-d278-04e3614201bd"
      },
      "source": [
        "input_dict=['-PAD-']\n",
        "target_dict=['-PAD-']\n",
        "eng_alphabets = 'abcdefghijklmnopqrstuvwxyz'\n",
        "pad_char = '-PAD-'\n",
        "\n",
        "eng_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(eng_alphabets):\n",
        "    eng_alpha2index[alpha] = index+1\n",
        "    input_dict.append(alpha)\n",
        "\n",
        "print(eng_alpha2index)\n",
        "print(input_dict)\n",
        "# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n",
        "\n",
        "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(hindi_alphabets):\n",
        "    hindi_alpha2index[alpha] = index+1\n",
        "    target_dict.append(alpha)\n",
        "    #print(alpha)\n",
        "\n",
        "print(hindi_alpha2index)\n",
        "print(target_dict)\n",
        "\n",
        "\n",
        "# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n",
        "\n",
        "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_index2alpha = {0: pad_char}\n",
        "for index, alpha in enumerate(hindi_alphabets):\n",
        "    hindi_index2alpha[index+1] = alpha\n",
        "   # target_dict.append(alpha)\n",
        "    #print(alpha)\n",
        "\n",
        "print(hindi_index2alpha)\n",
        "\n",
        "eng_alphabets = 'abcdefghijklmnopqrstuvwxyz'\n",
        "eng_index2alpha = {0: pad_char}\n",
        "for index, alpha in enumerate(eng_alphabets):\n",
        "    eng_index2alpha[index+1] = alpha\n",
        "   # target_dict.append(alpha)\n",
        "    #print(alpha)\n",
        "\n",
        "print(eng_index2alpha)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
            "['-PAD-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n",
            "['-PAD-', 'ऀ', 'ँ', 'ं', 'ः', 'ऄ', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ऌ', 'ऍ', 'ऎ', 'ए', 'ऐ', 'ऑ', 'ऒ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'ऩ', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ऱ', 'ल', 'ळ', 'ऴ', 'व', 'श', 'ष', 'स', 'ह', 'ऺ', 'ऻ', '़', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'ॅ', 'ॆ', 'े', 'ै', 'ॉ', 'ॊ', 'ो', 'ौ', '्', 'ॎ', 'ॏ', 'ॐ', '॑', '॒', '॓', '॔', 'ॕ', 'ॖ', 'ॗ', 'क़', 'ख़', 'ग़', 'ज़', 'ड़', 'ढ़', 'फ़', 'य़', 'ॠ', 'ॡ', 'ॢ', 'ॣ', '।', '॥', '०', '१', '२', '३', '४', '५', '६', '७', '८', '९', '॰', 'ॱ', 'ॲ', 'ॳ', 'ॴ', 'ॵ', 'ॶ', 'ॷ', 'ॸ', 'ॹ', 'ॺ', 'ॻ', 'ॼ', 'ॽ', 'ॾ', 'ॿ']\n",
            "{0: '-PAD-', 1: 'ऀ', 2: 'ँ', 3: 'ं', 4: 'ः', 5: 'ऄ', 6: 'अ', 7: 'आ', 8: 'इ', 9: 'ई', 10: 'उ', 11: 'ऊ', 12: 'ऋ', 13: 'ऌ', 14: 'ऍ', 15: 'ऎ', 16: 'ए', 17: 'ऐ', 18: 'ऑ', 19: 'ऒ', 20: 'ओ', 21: 'औ', 22: 'क', 23: 'ख', 24: 'ग', 25: 'घ', 26: 'ङ', 27: 'च', 28: 'छ', 29: 'ज', 30: 'झ', 31: 'ञ', 32: 'ट', 33: 'ठ', 34: 'ड', 35: 'ढ', 36: 'ण', 37: 'त', 38: 'थ', 39: 'द', 40: 'ध', 41: 'न', 42: 'ऩ', 43: 'प', 44: 'फ', 45: 'ब', 46: 'भ', 47: 'म', 48: 'य', 49: 'र', 50: 'ऱ', 51: 'ल', 52: 'ळ', 53: 'ऴ', 54: 'व', 55: 'श', 56: 'ष', 57: 'स', 58: 'ह', 59: 'ऺ', 60: 'ऻ', 61: '़', 62: 'ऽ', 63: 'ा', 64: 'ि', 65: 'ी', 66: 'ु', 67: 'ू', 68: 'ृ', 69: 'ॄ', 70: 'ॅ', 71: 'ॆ', 72: 'े', 73: 'ै', 74: 'ॉ', 75: 'ॊ', 76: 'ो', 77: 'ौ', 78: '्', 79: 'ॎ', 80: 'ॏ', 81: 'ॐ', 82: '॑', 83: '॒', 84: '॓', 85: '॔', 86: 'ॕ', 87: 'ॖ', 88: 'ॗ', 89: 'क़', 90: 'ख़', 91: 'ग़', 92: 'ज़', 93: 'ड़', 94: 'ढ़', 95: 'फ़', 96: 'य़', 97: 'ॠ', 98: 'ॡ', 99: 'ॢ', 100: 'ॣ', 101: '।', 102: '॥', 103: '०', 104: '१', 105: '२', 106: '३', 107: '४', 108: '५', 109: '६', 110: '७', 111: '८', 112: '९', 113: '॰', 114: 'ॱ', 115: 'ॲ', 116: 'ॳ', 117: 'ॴ', 118: 'ॵ', 119: 'ॶ', 120: 'ॷ', 121: 'ॸ', 122: 'ॹ', 123: 'ॺ', 124: 'ॻ', 125: 'ॼ', 126: 'ॽ', 127: 'ॾ', 128: 'ॿ'}\n",
            "{0: '-PAD-', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ0aXzuU5ifS"
      },
      "source": [
        "def readXmlDataset(filename):\n",
        "        tsv_file = open(filename)\n",
        "        read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
        "        lang1_words = []\n",
        "        lang2_words = []\n",
        "\n",
        "        for row in read_tsv:\n",
        "            lang2_words.append(row[0])\n",
        "            lang1_words.append(row[1])\n",
        "            #print(row[0])\n",
        "\n",
        "        return lang1_words, lang2_words\n",
        "train_input_texts, train_target_texts = readXmlDataset('hi.translit.sampled.train.tsv')\n",
        "test_input_texts, test_target_texts = readXmlDataset('hi.translit.sampled.test.tsv')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYtIFIHz634J"
      },
      "source": [
        "def word_rep(word, letter2index, device = 'cpu'):\n",
        "    rep = np.zeros((len(word)+1,  129))\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        rep[letter_index][pos] = 1\n",
        "    pad_pos = letter2index[pad_char]\n",
        "    rep[letter_index+1][pad_pos] = 1\n",
        "    return rep\n",
        "\n",
        "def gt_rep(word, letter2index, device = 'cpu'):\n",
        "    gt_rep = np.zeros([len(word)+1, 1], dtype=np.long)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        gt_rep[letter_index][0] = pos\n",
        "    gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
        "    return gt_rep\n",
        "    word_rep('abc',eng_alpha2index).shape\n",
        "    x=gt_rep('abc',eng_alpha2index)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpXZ36j_5K3Y"
      },
      "source": [
        "def createDataset(dataset,letter2index):\n",
        "    X_train=[]\n",
        "    for i,data in enumerate(dataset):\n",
        "        #print(data)\n",
        "        X_train.append(word_rep(data,letter2index))\n",
        "    X_train = np.array(X_train)\n",
        "    return X_train"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvYUB4gv6BTu",
        "outputId": "79d77491-80f1-4da7-d839-0133130fb458"
      },
      "source": [
        "X_train = createDataset(train_input_texts,eng_alpha2index)\n",
        "y_train = createDataset(train_target_texts,hindi_alpha2index)\n",
        "X_test = createDataset(test_input_texts,eng_alpha2index)\n",
        "y_test = createDataset(test_target_texts,hindi_alpha2index)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vW1ewK688Cfg",
        "outputId": "9fe6797a-1777-4827-b52c-95f1895fa345"
      },
      "source": [
        "print(len(eng_alpha2index))\n",
        "#a=[0]*(len(eng_alpha2index)-1)\n",
        "a=[0]*128\n",
        "eng_pad=[1]\n",
        "eng_pad=eng_pad+a\n",
        "print(eng_pad)\n",
        "print(len(hindi_alpha2index))\n",
        "a=[0]*128\n",
        "hindi_pad=[1]\n",
        "hindi_pad=hindi_pad+a\n",
        "print(hindi_pad)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27\n",
            "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "129\n",
            "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nczkBT69KdWd"
      },
      "source": [
        "def one_hot_encode(sequence, n_unique):\n",
        "\tencoding = list()\n",
        "\tfor value in sequence:\n",
        "\t\tvector = [0 for _ in range(n_unique)]\n",
        "\t\tvector[value] = 1\n",
        "\t\tencoding.append(vector)\n",
        "\treturn array(encoding)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH7o-dfEKxHf",
        "outputId": "6371673d-0bfb-4313-e441-3c2a006f65e2"
      },
      "source": [
        "one_hot_encode([1,2,3],10)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ABSEIPIcGLnX",
        "outputId": "e0283afb-8de9-4403-f15c-3677e5a5c53e"
      },
      "source": [
        "'''def one_hot_decode(encoded_seq):\n",
        "\treturn [argmax(vector) for vector in encoded_seq]\n",
        "d=one_hot_decode(y_train_padded[5])\n",
        "c=hindi_index2alpha[6]+hindi_index2alpha[3]+hindi_index2alpha[22]+hindi_index2alpha[66]+hindi_index2alpha[49]+hindi_index2alpha[64]+hindi_index2alpha[37]+hindi_index2alpha[0]\n",
        "c'''"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'def one_hot_decode(encoded_seq):\\n\\treturn [argmax(vector) for vector in encoded_seq]\\nd=one_hot_decode(y_train_padded[5])\\nc=hindi_index2alpha[6]+hindi_index2alpha[3]+hindi_index2alpha[22]+hindi_index2alpha[66]+hindi_index2alpha[49]+hindi_index2alpha[64]+hindi_index2alpha[37]+hindi_index2alpha[0]\\nc'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSce-sL4HWTr",
        "outputId": "be477681-e080-406b-8c9a-3157f8b558a4"
      },
      "source": [
        "max_input_sequence= max(len(seq) for seq in X_train)\n",
        "max_output_sequence= max(len(seq) for seq in y_train)\n",
        "\n",
        "print('max_input_sequence: ', max_input_sequence)\n",
        "print('max_output_sequence: ', max_output_sequence)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_input_sequence:  21\n",
            "max_output_sequence:  20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2abm43MfHWWG",
        "outputId": "afc2df49-51fc-4e98-a8b0-1ce2d6b6682c"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "X_train_padded = pad_sequences(X_train, maxlen= max_input_sequence, padding='post', value=eng_pad)\n",
        "print(\"X_train shape: \",X_train.shape)\n",
        "print(\"X_train_padded shape: \",X_train_padded.shape)\n",
        "\n",
        "y_train_padded = pad_sequences(y_train, maxlen= max_output_sequence, padding='post', value=hindi_pad)\n",
        "print(\"y_train shape: \",y_train.shape)\n",
        "print(\"y_train_padded shape: \",y_train_padded.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape:  (44204,)\n",
            "X_train_padded shape:  (44204, 21, 129)\n",
            "y_train shape:  (44204,)\n",
            "y_train_padded shape:  (44204, 20, 129)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wvw10trdHWY8",
        "outputId": "3b594ea8-367a-468a-f5a7-baedd19db458"
      },
      "source": [
        "i=0\n",
        "print(\"____Sample Input (Raw Format)____\")\n",
        "print(\"Original:\\n\", one_hot_decode(X_train[i]))\n",
        "print(\"Padded:\\n\",one_hot_decode(X_train_padded[i]))\n",
        "print(\"____Corresponding Output (Raw Format)____\")\n",
        "print(\"Original:\\n\", one_hot_decode(y_train[i]))\n",
        "print(\"Padded:\\n\",one_hot_decode(y_train_padded[i]))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "____Sample Input (Raw Format)____\n",
            "Original:\n",
            " [1, 14, 0]\n",
            "Padded:\n",
            " [1, 14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "____Corresponding Output (Raw Format)____\n",
            "Original:\n",
            " [6, 3, 0]\n",
            "Padded:\n",
            " [6, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN97C-THHWbb",
        "outputId": "b391df3d-2e0b-44d5-8a8d-12fc0e80e46c"
      },
      "source": [
        "X_test_padded = pad_sequences(X_test, maxlen= max_input_sequence, padding='post', \n",
        "                              value=eng_pad)\n",
        "print(\"X_test shape: \",X_test.shape)\n",
        "print(\"X_test_padded shape: \",X_test_padded.shape)\n",
        "\n",
        "y_test_padded = pad_sequences(y_test, maxlen= max_output_sequence, padding='post', \n",
        "                              value=hindi_pad)\n",
        "print(\"y_test shape: \",y_test.shape)\n",
        "print(\"y_test_padded shape: \",y_test_padded.shape)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_test shape:  (4502,)\n",
            "X_test_padded shape:  (4502, 21, 129)\n",
            "y_test shape:  (4502,)\n",
            "y_test_padded shape:  (4502, 20, 129)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWoyVxRZHWeH",
        "outputId": "f09042a6-d9e8-4628-8187-1c08ad6e2213"
      },
      "source": [
        "#Prepare TRAIN data set\n",
        "input_dimension = len(hindi_alpha2index)   #@param {type:\"integer\"}\n",
        "encoder_input_data = X_train_padded.copy()\n",
        "decoder_target_data = y_train_padded.copy()\n",
        "decoder_input_data = decoder_target_data.copy()\n",
        "for i, samples in enumerate(decoder_target_data):\n",
        "  seq = one_hot_decode(samples)\n",
        "  shifted= shift(seq, 1, cval=0)\n",
        "  decoder_input_data[i]=one_hot_encode(shifted,input_dimension)\n",
        "print(\"Data for Train\")\n",
        "print('encoder_input_data (X): ', one_hot_decode(encoder_input_data[1]))\n",
        "print('decoder_input_data (teacher forcing): ',one_hot_decode(decoder_input_data[1]))\n",
        "print('decoder_target_data (y):',one_hot_decode(decoder_target_data[1]))\n",
        "print(encoder_input_data.shape)\n",
        "\n",
        "#Prepare TEST data set\n",
        "encoder_input_test = X_test_padded.copy()\n",
        "decoder_target_test = y_test_padded.copy()\n",
        "decoder_input_test= decoder_target_test.copy()\n",
        "for i, samples in enumerate(decoder_target_test):\n",
        "  seq = one_hot_decode(samples)\n",
        "  shifted= shift(seq, 1, cval=0)\n",
        "  decoder_input_test[i]=one_hot_encode(shifted,input_dimension)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data for Train\n",
            "encoder_input_data (X):  [1, 14, 11, 7, 1, 14, 9, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "decoder_input_data (teacher forcing):  [0, 6, 3, 22, 24, 36, 64, 37, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "decoder_target_data (y): [6, 3, 22, 24, 36, 64, 37, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "(44204, 21, 129)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqowG_YaRNUX"
      },
      "source": [
        "#@title LSTMoutputDimension\n",
        "LSTMoutputDimension = 32 #@param {type:\"integer\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtlvelkFHWgz"
      },
      "source": [
        "# Define an input sequence and process it.\n",
        "encoder_inputs= Input(shape=(max_input_sequence, input_dimension), name='encoder_inputs')\n",
        "\n",
        "masking = tf.keras.layers.Masking(mask_value= hindi_pad)\n",
        "encoder_inputs_masked = masking(encoder_inputs)\n",
        "\n",
        "\n",
        "encoder_lstm=LSTM(LSTMoutputDimension, return_state=True, name='encoder_lstm')\n",
        "LSTM_outputs, state_h, state_c = encoder_lstm(encoder_inputs_masked)\n",
        "\n",
        "\n",
        "# We discard `LSTM_outputs` and only keep the other states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "\n",
        "\n",
        "decoder_inputs = Input(shape=(None, input_dimension), name='decoder_inputs')\n",
        "decoder_lstm = LSTM(LSTMoutputDimension, return_sequences=True, return_state=True, name='decoder_lstm')\n",
        "\n",
        "# Set up the decoder, using `context vector` as initial state.\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
        "                                     initial_state=encoder_states)\n",
        "\n",
        "#complete the decoder model by adding a Dense layer with Softmax activation function \n",
        "#for prediction of the next output\n",
        "#Dense layer will output one-hot encoded representation as we did for input\n",
        "#Therefore, we will use input_dimension number of neurons\n",
        "decoder_dense = Dense(input_dimension, activation='softmax', name='decoder_dense')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# put together\n",
        "model_encoder_training = Model([encoder_inputs, decoder_inputs], decoder_outputs, name='model_encoder_training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0eCYltpHWkW"
      },
      "source": [
        "model_encoder_training.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_encoder_training.summary()\n",
        "plot_model(model_encoder_training, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnYEE-WfRdzg"
      },
      "source": [
        "model_encoder_training.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
        "          batch_size=64,\n",
        "          epochs=100,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2Uhhi5OV5zK"
      },
      "source": [
        "#@title Function to Train & Test  given model (Early Stopping monitor 'val_loss')\n",
        "def train_test(model, X_train, y_train , X_test, \ty_test, epochs=500, batch_size=32, patience=5,verbose=0):\n",
        "\t# patient early stopping\n",
        "\t#es = EarlyStopping(monitor='val_accuracy', mode='max', min_delta=1, patience=20)\n",
        "\tes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=patience)\n",
        "\t# train model\n",
        "\tprint('training for ',epochs,' epochs begins with EarlyStopping(monitor= val_loss, patience=',patience,')....')\n",
        "\thistory=model.fit(X_train, y_train, validation_split= 0.1, epochs=epochs,batch_size=batch_size, verbose=verbose, callbacks=[es])\n",
        "\tprint(epochs,' epoch training finished...')\n",
        "\n",
        "\t# report training\n",
        "\t# list all data in history\n",
        "\t#print(history.history.keys())\n",
        "\t# evaluate the model\n",
        "\t_, train_acc = model.evaluate(X_train, y_train, batch_size=batch_size, verbose=0)\n",
        "\t_, test_acc = model.evaluate(X_test, \ty_test, batch_size=batch_size, verbose=0)\n",
        "\tprint('\\nPREDICTION ACCURACY (%):')\n",
        "\tprint('Train: %.3f, Test: %.3f' % (train_acc*100, test_acc*100))\n",
        "\t# summarize history for accuracy\n",
        "\tplt.plot(history.history['accuracy'])\n",
        "\tplt.plot(history.history['val_accuracy'])\n",
        "\tplt.title(model.name+' accuracy')\n",
        "\tplt.ylabel('accuracy')\n",
        "\tplt.xlabel('epoch')\n",
        "\tplt.legend(['train', 'val'], loc='upper left')\n",
        "\tplt.show()\n",
        "\t# summarize history for loss\n",
        "\tplt.plot(history.history['loss'])\n",
        "\tplt.plot(history.history['val_loss'])\n",
        "\tplt.title(model.name+' loss')\n",
        "\tplt.ylabel('loss')\n",
        "\tplt.xlabel('epoch')\n",
        "\tplt.legend(['train', 'val'], loc='upper left')\n",
        "\tplt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\t# spot check some examples\n",
        "\tspace = 3*len(one_hot_decode(y_test[0]))\n",
        "\tprint('10 examples from test data...')\n",
        "\tprint('Input',' '*(space-4) ,'Expected',' '*(space-7) ,\n",
        "\t      'Predicted',' '*(space-5) ,'T/F')\n",
        "\tcorrect =0 \n",
        "\tsampleNo =  1000\n",
        "\n",
        "\tpredicted= model.predict(X_test[:sampleNo], batch_size=batch_size)\n",
        "\tfor sample in range(0,sampleNo):\n",
        "\t\tif (one_hot_decode(y_test[sample])== one_hot_decode(predicted[sample])):\n",
        "\t\t\tcorrect+=1\n",
        "\t\tprint( one_hot_decode(X_test[0][sample]), ' ', \n",
        "\t\t\t\t\tone_hot_decode(y_test[sample]),' ', one_hot_decode(predicted[sample]),\n",
        "\t\t\t\t\t' ',one_hot_decode(y_test[sample])== one_hot_decode(predicted[sample]))\n",
        "\tprint('Accuracy: ', correct/sampleNo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I46w57yWTHJw"
      },
      "source": [
        "train_test(model_encoder_training, [encoder_input_data, decoder_input_data], decoder_target_data ,\n",
        "           [encoder_input_test, decoder_input_test], \n",
        "           decoder_target_test, epochs=100, batch_size=64, patience=3,verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2sAjDTSTT2F"
      },
      "source": [
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_C54WtATeQ9"
      },
      "source": [
        "decoder_state_input_h = Input(shape=(LSTMoutputDimension,))\n",
        "decoder_state_input_c = Input(shape=(LSTMoutputDimension,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_h, state_c]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs] + decoder_states)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1eEuWStTfx0"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, input_dimension))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, 0] = 1 \n",
        "    # START (0 zero) in one-hot-encoding --> [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_seq = list()\n",
        "    while not stop_condition:\n",
        "\n",
        "        # in a loop\n",
        "        # decode the input to a token/output prediction + required states for context vector\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value)\n",
        "\n",
        "        # convert the token/output prediction to a token/output\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = sampled_token_index\n",
        "        # add the predicted token/output to output sequence\n",
        "        decoded_seq.append(sampled_char)\n",
        "        \n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == 0 or\n",
        "           len(decoded_seq) == max_output_sequence):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the input target sequence (of length 1) \n",
        "        # with the predicted token/output \n",
        "        target_seq = np.zeros((1, 1, input_dimension))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # Update input states (context vector) \n",
        "        # with the ouputed states\n",
        "        states_value = [h, c]\n",
        "\n",
        "        # loop back.....\n",
        "        \n",
        "    # when loop exists return the output sequence\n",
        "    return decoded_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7m2a-EOTlNa"
      },
      "source": [
        "print('Input \\t\\t\\t\\t\\t  Expected  \\t\\t\\t   Predicted \\t\\t\\t\\t\\t\\t\\t T/F')\n",
        "correct =0 \n",
        "sampleNo =  1000\n",
        "for sample in range(0,sampleNo):\n",
        "  predicted= decode_sequence(encoder_input_data[sample].reshape(1,max_input_sequence,input_dimension))\n",
        "  if (one_hot_decode(decoder_target_data[sample])== predicted+ [0] * (max_output_sequence- len(predicted))):\n",
        "    correct+=1\n",
        "  print( one_hot_decode(encoder_input_data[sample]), '\\t\\t', \n",
        "        one_hot_decode(decoder_target_data[sample]),'\\t', predicted,\n",
        "        '\\t\\t',one_hot_decode(decoder_target_data[sample])== predicted+ [0] * (max_output_sequence- len(predicted)))\n",
        "print('Accuracy: ', correct/sampleNo)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}