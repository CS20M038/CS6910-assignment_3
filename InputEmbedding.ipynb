{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InputEmbedding.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CS20M038/CS6910-assignment_3/blob/main/InputEmbedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZp3QKozCR18"
      },
      "source": [
        "#@title Import Libraries\n",
        "from random import randint\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "import keras.backend as K\n",
        "from tensorflow.keras import models\n",
        "from numpy import array_equal\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import LSTM, Bidirectional\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "from tensorflow.keras.layers import RepeatVector\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.layers import Lambda\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "from scipy.ndimage.interpolation import shift\n",
        "import csv\n",
        "import random\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import one_hot\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abEd7jJ1SmTq",
        "outputId": "6e329c78-6119-4027-901f-966a2a9d594b"
      },
      "source": [
        "input_dict=['-PAD-']\n",
        "target_dict=['-PAD-']\n",
        "eng_alphabets = 'abcdefghijklmnopqrstuvwxyz'\n",
        "pad_char = '-PAD-'\n",
        "\n",
        "eng_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(eng_alphabets):\n",
        "    eng_alpha2index[alpha] = index+1\n",
        "    input_dict.append(alpha)\n",
        "\n",
        "print(eng_alpha2index)\n",
        "print(input_dict)\n",
        "# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n",
        "\n",
        "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(hindi_alphabets):\n",
        "    hindi_alpha2index[alpha] = index+1\n",
        "    target_dict.append(alpha)\n",
        "    #print(alpha)\n",
        "\n",
        "print(hindi_alpha2index)\n",
        "print(target_dict)\n",
        "\n",
        "\n",
        "# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n",
        "\n",
        "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_index2alpha = {0: pad_char}\n",
        "for index, alpha in enumerate(hindi_alphabets):\n",
        "    hindi_index2alpha[index+1] = alpha\n",
        "   # target_dict.append(alpha)\n",
        "    #print(alpha)\n",
        "\n",
        "print(hindi_index2alpha)\n",
        "\n",
        "eng_alphabets = 'abcdefghijklmnopqrstuvwxyz'\n",
        "eng_index2alpha = {0: pad_char}\n",
        "for index, alpha in enumerate(eng_alphabets):\n",
        "    eng_index2alpha[index+1] = alpha\n",
        "   # target_dict.append(alpha)\n",
        "    #print(alpha)\n",
        "\n",
        "print(eng_index2alpha)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
            "['-PAD-', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n",
            "['-PAD-', 'ऀ', 'ँ', 'ं', 'ः', 'ऄ', 'अ', 'आ', 'इ', 'ई', 'उ', 'ऊ', 'ऋ', 'ऌ', 'ऍ', 'ऎ', 'ए', 'ऐ', 'ऑ', 'ऒ', 'ओ', 'औ', 'क', 'ख', 'ग', 'घ', 'ङ', 'च', 'छ', 'ज', 'झ', 'ञ', 'ट', 'ठ', 'ड', 'ढ', 'ण', 'त', 'थ', 'द', 'ध', 'न', 'ऩ', 'प', 'फ', 'ब', 'भ', 'म', 'य', 'र', 'ऱ', 'ल', 'ळ', 'ऴ', 'व', 'श', 'ष', 'स', 'ह', 'ऺ', 'ऻ', '़', 'ऽ', 'ा', 'ि', 'ी', 'ु', 'ू', 'ृ', 'ॄ', 'ॅ', 'ॆ', 'े', 'ै', 'ॉ', 'ॊ', 'ो', 'ौ', '्', 'ॎ', 'ॏ', 'ॐ', '॑', '॒', '॓', '॔', 'ॕ', 'ॖ', 'ॗ', 'क़', 'ख़', 'ग़', 'ज़', 'ड़', 'ढ़', 'फ़', 'य़', 'ॠ', 'ॡ', 'ॢ', 'ॣ', '।', '॥', '०', '१', '२', '३', '४', '५', '६', '७', '८', '९', '॰', 'ॱ', 'ॲ', 'ॳ', 'ॴ', 'ॵ', 'ॶ', 'ॷ', 'ॸ', 'ॹ', 'ॺ', 'ॻ', 'ॼ', 'ॽ', 'ॾ', 'ॿ']\n",
            "{0: '-PAD-', 1: 'ऀ', 2: 'ँ', 3: 'ं', 4: 'ः', 5: 'ऄ', 6: 'अ', 7: 'आ', 8: 'इ', 9: 'ई', 10: 'उ', 11: 'ऊ', 12: 'ऋ', 13: 'ऌ', 14: 'ऍ', 15: 'ऎ', 16: 'ए', 17: 'ऐ', 18: 'ऑ', 19: 'ऒ', 20: 'ओ', 21: 'औ', 22: 'क', 23: 'ख', 24: 'ग', 25: 'घ', 26: 'ङ', 27: 'च', 28: 'छ', 29: 'ज', 30: 'झ', 31: 'ञ', 32: 'ट', 33: 'ठ', 34: 'ड', 35: 'ढ', 36: 'ण', 37: 'त', 38: 'थ', 39: 'द', 40: 'ध', 41: 'न', 42: 'ऩ', 43: 'प', 44: 'फ', 45: 'ब', 46: 'भ', 47: 'म', 48: 'य', 49: 'र', 50: 'ऱ', 51: 'ल', 52: 'ळ', 53: 'ऴ', 54: 'व', 55: 'श', 56: 'ष', 57: 'स', 58: 'ह', 59: 'ऺ', 60: 'ऻ', 61: '़', 62: 'ऽ', 63: 'ा', 64: 'ि', 65: 'ी', 66: 'ु', 67: 'ू', 68: 'ृ', 69: 'ॄ', 70: 'ॅ', 71: 'ॆ', 72: 'े', 73: 'ै', 74: 'ॉ', 75: 'ॊ', 76: 'ो', 77: 'ौ', 78: '्', 79: 'ॎ', 80: 'ॏ', 81: 'ॐ', 82: '॑', 83: '॒', 84: '॓', 85: '॔', 86: 'ॕ', 87: 'ॖ', 88: 'ॗ', 89: 'क़', 90: 'ख़', 91: 'ग़', 92: 'ज़', 93: 'ड़', 94: 'ढ़', 95: 'फ़', 96: 'य़', 97: 'ॠ', 98: 'ॡ', 99: 'ॢ', 100: 'ॣ', 101: '।', 102: '॥', 103: '०', 104: '१', 105: '२', 106: '३', 107: '४', 108: '५', 109: '६', 110: '७', 111: '८', 112: '९', 113: '॰', 114: 'ॱ', 115: 'ॲ', 116: 'ॳ', 117: 'ॴ', 118: 'ॵ', 119: 'ॶ', 120: 'ॷ', 121: 'ॸ', 122: 'ॹ', 123: 'ॺ', 124: 'ॻ', 125: 'ॼ', 126: 'ॽ', 127: 'ॾ', 128: 'ॿ'}\n",
            "{0: '-PAD-', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8m0MsspSwZb"
      },
      "source": [
        "def readXmlDataset(filename):\n",
        "        tsv_file = open(filename)\n",
        "        read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
        "        lang1_words = []\n",
        "        lang2_words = []\n",
        "\n",
        "        for row in read_tsv:\n",
        "            lang2_words.append(row[0])\n",
        "            lang1_words.append(row[1])\n",
        "            #print(row[0])\n",
        "\n",
        "        return lang1_words, lang2_words\n",
        "train_input_texts, train_target_texts = readXmlDataset('hi.translit.sampled.train.tsv')\n",
        "test_input_texts, test_target_texts = readXmlDataset('hi.translit.sampled.test.tsv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ck5H9-yvlCtg",
        "outputId": "2205bcb2-c32b-4af9-9f30-3e151ddcb65e"
      },
      "source": [
        "def gt_integer_code(word, letter2index, device = 'cpu'):\n",
        "    gt_rep = []\n",
        "    #print(gt_rep)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        gt_rep.append(pos)\n",
        "    gt_rep.append(letter2index[pad_char])\n",
        "    return gt_rep\n",
        "#print(word_rep('abc',eng_alpha2index))\n",
        "gt_integer_code('abc',eng_alpha2index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-9mL3FnlqNh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11d37deb-0ca1-4062-ad28-40ea1592cc6d"
      },
      "source": [
        "def doc_integer_code(doc,letter2index):\n",
        "    doc_integer_coded=[]\n",
        "    for i, data in enumerate(doc):\n",
        "        doc_integer_coded.append(gt_integer_code(data,letter2index))\n",
        "    return doc_integer_coded\n",
        "doc_integer_code(train_input_texts[0:5],eng_alpha2index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 14, 0],\n",
              " [1, 14, 11, 7, 1, 14, 9, 20, 0],\n",
              " [21, 14, 3, 12, 5, 0],\n",
              " [1, 14, 11, 21, 18, 0],\n",
              " [1, 14, 11, 21, 18, 1, 14, 0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9HN6sxWmmqf",
        "outputId": "d6b11f3c-85aa-4eb5-af60-c5867f8a106e"
      },
      "source": [
        "encoded_docs=doc_integer_code(train_input_texts,eng_alpha2index)\n",
        "max_length = 25\n",
        "vocab_size = 27\n",
        "padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "# define the model\n",
        "model_embed = Sequential()\n",
        "model_embed.add(Embedding(vocab_size, 8, input_length=max_length))\n",
        "model_embed.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# summarize the model\n",
        "print(model_embed.summary())\n",
        "output_array = model_embed.predict(padded_docs)\n",
        "print(output_array.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 25, 8)             216       \n",
            "=================================================================\n",
            "Total params: 216\n",
            "Trainable params: 216\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "(44204, 25, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awn3QoceT2Sj",
        "outputId": "48001f48-8085-46fa-a6d4-478bab5f11c3"
      },
      "source": [
        "output_array[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.03793967, -0.0124194 ,  0.0095832 ,  0.02267021,  0.04866118,\n",
              "         0.00968114, -0.02523437, -0.02529996],\n",
              "       [-0.04673539,  0.01019722,  0.02276536, -0.02871223, -0.03260108,\n",
              "        -0.01375018, -0.04266194, -0.01933085],\n",
              "       [-0.03664898,  0.04865488,  0.03286825, -0.04360212, -0.00460941,\n",
              "         0.01637304, -0.03167987, -0.02501484],\n",
              "       [ 0.01385424, -0.00999112,  0.01493018, -0.01882696, -0.00479795,\n",
              "         0.03220458, -0.00337058, -0.0257418 ],\n",
              "       [-0.03793967, -0.0124194 ,  0.0095832 ,  0.02267021,  0.04866118,\n",
              "         0.00968114, -0.02523437, -0.02529996],\n",
              "       [-0.04673539,  0.01019722,  0.02276536, -0.02871223, -0.03260108,\n",
              "        -0.01375018, -0.04266194, -0.01933085],\n",
              "       [ 0.01242529, -0.00254051,  0.00508539, -0.03158293, -0.0012924 ,\n",
              "         0.04602196, -0.03291297,  0.00354161],\n",
              "       [-0.02602918, -0.00411272,  0.02756573,  0.03020208,  0.04517576,\n",
              "         0.03870547,  0.03335622,  0.03415782],\n",
              "       [ 0.03326741,  0.00168619, -0.04120141,  0.0241004 ,  0.00669147,\n",
              "        -0.03128184,  0.04337433,  0.01262081],\n",
              "       [ 0.03326741,  0.00168619, -0.04120141,  0.0241004 ,  0.00669147,\n",
              "        -0.03128184,  0.04337433,  0.01262081],\n",
              "       [ 0.03326741,  0.00168619, -0.04120141,  0.0241004 ,  0.00669147,\n",
              "        -0.03128184,  0.04337433,  0.01262081],\n",
              "       [ 0.03326741,  0.00168619, -0.04120141,  0.0241004 ,  0.00669147,\n",
              "        -0.03128184,  0.04337433,  0.01262081],\n",
              "       [ 0.03326741,  0.00168619, -0.04120141,  0.0241004 ,  0.00669147,\n",
              "        -0.03128184,  0.04337433,  0.01262081],\n",
              "       [ 0.03326741,  0.00168619, -0.04120141,  0.0241004 ,  0.00669147,\n",
              "        -0.03128184,  0.04337433,  0.01262081],\n",
              "       [ 0.03326741,  0.00168619, -0.04120141,  0.0241004 ,  0.00669147,\n",
              "        -0.03128184,  0.04337433,  0.01262081],\n",
              "       [ 0.03326741,  0.00168619, -0.04120141,  0.0241004 ,  0.00669147,\n",
              "        -0.03128184,  0.04337433,  0.01262081],\n",
              "       [ 0.03326741,  0.00168619, -0.04120141,  0.0241004 ,  0.00669147,\n",
              "        -0.03128184,  0.04337433,  0.01262081],\n",
              "       [ 0.03326741,  0.00168619, -0.04120141,  0.0241004 ,  0.00669147,\n",
              "        -0.03128184,  0.04337433,  0.01262081],\n",
              "       [ 0.03326741,  0.00168619, -0.04120141,  0.0241004 ,  0.00669147,\n",
              "        -0.03128184,  0.04337433,  0.01262081],\n",
              "       [ 0.03326741,  0.00168619, -0.04120141,  0.0241004 ,  0.00669147,\n",
              "        -0.03128184,  0.04337433,  0.01262081],\n",
              "       [ 0.03326741,  0.00168619, -0.04120141,  0.0241004 ,  0.00669147,\n",
              "        -0.03128184,  0.04337433,  0.01262081],\n",
              "       [ 0.03326741,  0.00168619, -0.04120141,  0.0241004 ,  0.00669147,\n",
              "        -0.03128184,  0.04337433,  0.01262081],\n",
              "       [ 0.03326741,  0.00168619, -0.04120141,  0.0241004 ,  0.00669147,\n",
              "        -0.03128184,  0.04337433,  0.01262081],\n",
              "       [ 0.03326741,  0.00168619, -0.04120141,  0.0241004 ,  0.00669147,\n",
              "        -0.03128184,  0.04337433,  0.01262081],\n",
              "       [ 0.03326741,  0.00168619, -0.04120141,  0.0241004 ,  0.00669147,\n",
              "        -0.03128184,  0.04337433,  0.01262081]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    }
  ]
}